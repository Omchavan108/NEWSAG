"""
NewsAura AI Chatbot Router
--------------------------
Context-aware personal news assistant that uses ONLY user's saved data.
NO external news calls. NO hallucinations.

Uses Ollama LLM for natural conversational responses with safe fallbacks.
"""

import logging
import re
from datetime import datetime
from typing import Optional
from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel

from app.core.database import get_db
from app.core.auth import get_current_user_optional
from app.core.cache import get_from_cache
from app.services.summarizer import TextSummarizer
from app.services.chat_llm import chat_llm, get_fallback_message

# Categories matching the news feed cache keys
NEWS_CATEGORIES = ["general", "nation", "business", "technology", "sports", "entertainment", "health"]

router = APIRouter()
logger = logging.getLogger(__name__)
summarizer = TextSummarizer()


# --------------------------------------------------
# Request / Response Models
# --------------------------------------------------
class ChatMessageRequest(BaseModel):
    message: str
    context: Optional[dict] = None  # e.g., {"article_id": "..."}


class ChatMessageResponse(BaseModel):
    reply: str
    intent: str
    sources: list[str] = []


# --------------------------------------------------
# Intent Detection (Rule-Based)
# --------------------------------------------------
INTENT_PATTERNS = {
    "summarize_saved": [
        r"summarize.*saved",
        r"summarize.*bookmarks?",
        r"summarize.*articles?",
        r"what.*saved",
        r"my.*saved.*articles?",
    ],
    "daily_briefing": [
        r"today.*briefing",
        r"daily.*briefing",
        r"news.*today",
        r"what.*happening",
        r"catch.*up",
        r"brief.*me",
    ],
    "article_qa": [
        r"about.*this.*article",
        r"what.*this.*article",
        r"explain.*article",
        r"tell.*me.*about",
        r"what.*does.*say",
    ],
    "top_topics": [
        r"what.*topics?.*read",
        r"top.*categor",
        r"favorite.*topics?",
        r"most.*read",
        r"reading.*habits?",
    ],
    "sentiment_insight": [
        r"why.*negative",
        r"why.*positive",
        r"sentiment",
        r"mood.*feed",
        r"tone.*articles?",
    ],
    "read_recommendation": [
        r"what.*should.*read",
        r"recommend",
        r"suggest.*article",
        r"read.*first",
        r"priority",
    ],
    "explain_simple": [
        r"explain.*like.*[0-9]",
        r"simple.*terms",
        r"eli5",
        r"simplify",
        r"dumb.*down",
    ],
    "compare_articles": [
        r"compare",
        r"difference.*between",
        r"similar.*articles?",
    ],
    "similar_read": [
        r"read.*similar",
        r"something.*like",
        r"related.*articles?",
    ],
    "greeting": [
        r"^hi$",
        r"^hello",
        r"^hey",
        r"^good\s",
    ],
    "help": [
        r"help",
        r"what.*can.*you",
        r"capabilities",
    ],
    "news_feed": [
        r"latest.*news",
        r"current.*news",
        r"today.*news",
        r"trending",
        r"what.*news",
        r"any.*news.*about",
        r"tell.*about.*news",
        r"feed",
        r"headlines?",
    ],
}


def detect_intent(message: str) -> str:
    """Detect user intent from message using keyword patterns."""
    message_lower = message.lower().strip()
    
    for intent, patterns in INTENT_PATTERNS.items():
        for pattern in patterns:
            if re.search(pattern, message_lower):
                return intent
    
    return "general_query"


# --------------------------------------------------
# Context Aggregation Helpers
# --------------------------------------------------
async def get_user_bookmarks(db, user_id: str, limit: int = 20) -> list:
    """Fetch user's recent bookmarks."""
    cursor = db.bookmarks.find(
        {"user_id": user_id}
    ).sort("created_at", -1).limit(limit)
    
    return [doc async for doc in cursor]


async def get_user_read_later(db, user_id: str, limit: int = 20) -> list:
    """Fetch user's read later items."""
    cursor = db.read_later.find(
        {"user_id": user_id}
    ).sort("created_at", -1).limit(limit)
    
    return [doc async for doc in cursor]


async def get_user_summaries(db, user_id: str, limit: int = 10) -> list:
    """Fetch user's summary logs."""
    cursor = db.summary_logs.find(
        {"user_id": user_id}
    ).sort("created_at", -1).limit(limit)
    
    return [doc async for doc in cursor]


async def get_cached_news_articles(limit_per_category: int = 10) -> list:
    """Fetch cached news articles from Redis (the actual news feed)."""
    all_articles = []
    seen_ids = set()
    for category in NEWS_CATEGORIES:
        cache_key = f"gnews:{category}"
        cached = await get_from_cache(cache_key)
        if not cached:
            continue
        for article in cached[:limit_per_category]:
            article_id = article.get("id") or article.get("url")
            if article_id and article_id not in seen_ids:
                seen_ids.add(article_id)
                all_articles.append(article)
    return all_articles


async def find_article_in_cache(article_id: str) -> Optional[dict]:
    """Find a specific article in the Redis news cache."""
    for category in NEWS_CATEGORIES:
        cache_key = f"gnews:{category}"
        cached = await get_from_cache(cache_key)
        if not cached:
            continue
        for article in cached:
            if article.get("id") == article_id or article.get("url") == article_id:
                return article
    return None


async def get_user_analytics(db, user_id: str) -> dict:
    """Get analytics data for the user."""
    bookmarks_count = await db.bookmarks.count_documents({"user_id": user_id})
    read_later_count = await db.read_later.count_documents({"user_id": user_id})
    articles_read = await db.summary_logs.count_documents({"user_id": user_id})
    
    # Category breakdown
    category_counts = {}
    for collection in (db.bookmarks, db.read_later):
        pipeline = [
            {"$match": {"user_id": user_id, "category": {"$exists": True, "$ne": None}}},
            {"$group": {"_id": "$category", "count": {"$sum": 1}}},
        ]
        async for row in collection.aggregate(pipeline):
            cat = row.get("_id")
            if cat:
                category_counts[cat] = category_counts.get(cat, 0) + row.get("count", 0)
    
    top_category = max(category_counts.items(), key=lambda x: x[1])[0] if category_counts else None
    
    # Sentiment breakdown
    sentiment_counts = {"Positive": 0, "Neutral": 0, "Negative": 0}
    for collection in (db.bookmarks, db.read_later):
        cursor = collection.find(
            {"user_id": user_id, "sentiment": {"$exists": True}},
            projection={"sentiment": 1}
        )
        async for row in cursor:
            sentiment = row.get("sentiment")
            if isinstance(sentiment, dict):
                label = sentiment.get("label")
                if label in sentiment_counts:
                    sentiment_counts[label] += 1
    
    return {
        "bookmarks_count": bookmarks_count,
        "read_later_count": read_later_count,
        "articles_read": articles_read,
        "total_saved": bookmarks_count + read_later_count,
        "top_category": top_category,
        "category_breakdown": category_counts,
        "sentiment_breakdown": sentiment_counts,
    }


async def get_article_by_id(db, user_id: str, article_id: str) -> Optional[dict]:
    """Find a specific article in user's saved items."""
    # Check bookmarks first
    article = await db.bookmarks.find_one({
        "user_id": user_id,
        "$or": [
            {"article_id": article_id},
            {"_id": article_id},
            {"url": {"$regex": article_id, "$options": "i"}},
        ]
    })
    
    if not article:
        # Check read later
        article = await db.read_later.find_one({
            "user_id": user_id,
            "$or": [
                {"article_id": article_id},
                {"_id": article_id},
                {"url": {"$regex": article_id, "$options": "i"}},
            ]
        })
    
    return article


# --------------------------------------------------
# Context Builder for LLM
# --------------------------------------------------
def build_llm_context(
    bookmarks: list,
    read_later: list,
    analytics: dict,
    article: Optional[dict] = None,
    intent: str = "general",
    cached_articles: Optional[list] = None,
) -> str:
    """
    Build a context string from user data for the LLM.
    This ensures the LLM ONLY has access to user's saved data.
    """
    context_parts = []
    
    # Add specific article context if provided
    if article:
        context_parts.append("=== CURRENT ARTICLE ===")
        context_parts.append(f"Title: {article.get('title', 'Untitled')}")
        source = article.get('source', 'Unknown')
        if isinstance(source, dict):
            source = source.get('name', 'Unknown')
        context_parts.append(f"Source: {source}")
        context_parts.append(f"Category: {article.get('category', 'general')}")
        if article.get('content'):
            context_parts.append(f"Content: {article.get('content')[:600]}")
        elif article.get('description'):
            context_parts.append(f"Description: {article.get('description')[:400]}")
        if isinstance(article.get('sentiment'), dict):
            sentiment = article['sentiment']
            context_parts.append(f"Sentiment: {sentiment.get('label', 'Unknown')}")
        context_parts.append("")
    
    # Add analytics summary
    context_parts.append("=== USER ANALYTICS ===")
    context_parts.append(f"Total saved articles: {analytics.get('total_saved', 0)}")
    context_parts.append(f"Bookmarks: {analytics.get('bookmarks_count', 0)}")
    context_parts.append(f"Read later items: {analytics.get('read_later_count', 0)}")
    context_parts.append(f"Articles summarized: {analytics.get('articles_read', 0)}")
    
    if analytics.get('top_category'):
        context_parts.append(f"Top category: {analytics['top_category']}")
    
    if analytics.get('category_breakdown'):
        cats = analytics['category_breakdown']
        context_parts.append(f"Category breakdown: {', '.join(f'{k}: {v}' for k, v in cats.items())}")
    
    if analytics.get('sentiment_breakdown'):
        sentiment = analytics['sentiment_breakdown']
        context_parts.append(f"Sentiment distribution: Positive={sentiment.get('Positive', 0)}, Neutral={sentiment.get('Neutral', 0)}, Negative={sentiment.get('Negative', 0)}")
    context_parts.append("")
    
    # Add recent bookmarks
    if bookmarks:
        context_parts.append("=== RECENT BOOKMARKS ===")
        for i, item in enumerate(bookmarks[:10], 1):
            title = item.get('title', 'Untitled')[:80]
            source = item.get('source', 'Unknown')
            cat = item.get('category', 'general')
            sentiment_info = ""
            if isinstance(item.get('sentiment'), dict):
                sentiment_info = f" [{item['sentiment'].get('label', '')}]"
            context_parts.append(f"{i}. {title} â€” {source} ({cat}){sentiment_info}")
        context_parts.append("")
    
    # Add read later items
    if read_later:
        context_parts.append("=== READ LATER ITEMS ===")
        for i, item in enumerate(read_later[:10], 1):
            title = item.get('title', 'Untitled')[:80]
            source = item.get('source', 'Unknown')
            cat = item.get('category', 'general')
            context_parts.append(f"{i}. {title} â€” {source} ({cat})")
        context_parts.append("")

    # Add cached news feed articles (skip if a specific article is already provided to keep context small)
    if cached_articles and not article:
        context_parts.append("=== CURRENT NEWS FEED (Latest Articles) ===")
        for i, item in enumerate(cached_articles[:8], 1):
            title = item.get('title', 'Untitled')[:80]
            source = item.get('source', 'Unknown')
            if isinstance(source, dict):
                source = source.get('name', 'Unknown')
            cat = item.get('category', 'general')
            context_parts.append(f"{i}. [{cat.upper()}] {title} â€” {source}")
        context_parts.append("")
    
    return "\n".join(context_parts)


# --------------------------------------------------
# Response Generators (Context-Bound) - FALLBACK
# --------------------------------------------------
SAFETY_PREFIX = """Answer ONLY using the provided context below.
If information is missing or insufficient, respond with:
"I don't have enough information to answer that based on your saved articles."

CONTEXT:
"""


def generate_summarize_saved_response(bookmarks: list, read_later: list) -> str:
    """Generate summary of user's saved articles."""
    all_items = bookmarks + read_later
    
    if not all_items:
        return "You don't have any saved articles yet. Start bookmarking articles you find interesting, and I'll help you summarize them!"
    
    # Group by category
    by_category = {}
    for item in all_items[:15]:  # Limit to recent 15
        cat = item.get("category", "general")
        if cat not in by_category:
            by_category[cat] = []
        by_category[cat].append(item.get("title", "Untitled"))
    
    response = f"ðŸ“š **Your Saved Articles Summary** ({len(all_items)} total)\n\n"
    
    for cat, titles in by_category.items():
        response += f"**{cat.title()}** ({len(titles)} articles):\n"
        for title in titles[:3]:
            response += f"  â€¢ {title[:60]}{'...' if len(title) > 60 else ''}\n"
        if len(titles) > 3:
            response += f"  â€¢ ...and {len(titles) - 3} more\n"
        response += "\n"
    
    return response.strip()


def generate_daily_briefing(bookmarks: list, read_later: list, analytics: dict) -> str:
    """Generate a daily briefing based on user's interests."""
    top_cat = analytics.get("top_category")
    all_items = bookmarks + read_later
    
    if not all_items:
        return "Good morning! You don't have any saved articles yet. Browse the news feed and save articles that interest you for personalized briefings."
    
    response = "ðŸ“° **Your Daily Briefing**\n\n"
    
    if top_cat:
        response += f"Based on your reading habits, you're most interested in **{top_cat}** news.\n\n"
    
    response += "**Recent Headlines from Your Saves:**\n"
    
    for item in all_items[:5]:
        title = item.get("title", "Untitled")
        source = item.get("source", "Unknown")
        sentiment = item.get("sentiment", {})
        sentiment_label = sentiment.get("label", "") if isinstance(sentiment, dict) else ""
        emoji = {"Positive": "ðŸŸ¢", "Negative": "ðŸ”´", "Neutral": "ðŸŸ¡"}.get(sentiment_label, "")
        
        response += f"â€¢ {emoji} **{title[:50]}{'...' if len(title) > 50 else ''}** â€” {source}\n"
    
    return response.strip()


def generate_article_qa_response(article: Optional[dict], question: str) -> str:
    """Answer questions about a specific article."""
    if not article:
        return "I couldn't find that article in your saved items. Make sure you've bookmarked or saved it to Read Later first."
    
    title = article.get("title", "Unknown title")
    source = article.get("source", "Unknown source")
    url = article.get("url", "")
    sentiment = article.get("sentiment", {})
    category = article.get("category", "general")
    
    response = f"ðŸ“„ **About this article:**\n\n"
    response += f"**Title:** {title}\n"
    response += f"**Source:** {source}\n"
    response += f"**Category:** {category.title()}\n"
    
    if isinstance(sentiment, dict) and sentiment.get("label"):
        confidence = sentiment.get("confidence", 0)
        response += f"**Sentiment:** {sentiment['label']} ({int(confidence * 100)}% confidence)\n"
    
    if url:
        response += f"\n[Read the full article]({url})"
    
    return response


def generate_top_topics_response(analytics: dict) -> str:
    """Explain user's reading patterns."""
    category_breakdown = analytics.get("category_breakdown", {})
    top_cat = analytics.get("top_category")
    total = analytics.get("total_saved", 0)
    
    if not category_breakdown:
        return "I don't have enough data about your reading patterns yet. Save more articles and I'll be able to tell you your favorite topics!"
    
    response = "ðŸ“Š **Your Reading Patterns**\n\n"
    
    if top_cat:
        response += f"Your top category is **{top_cat.title()}**!\n\n"
    
    response += "**Category Breakdown:**\n"
    sorted_cats = sorted(category_breakdown.items(), key=lambda x: x[1], reverse=True)
    
    for cat, count in sorted_cats[:5]:
        percentage = (count / total * 100) if total > 0 else 0
        bar = "â–ˆ" * int(percentage / 10) + "â–‘" * (10 - int(percentage / 10))
        response += f"â€¢ {cat.title()}: {bar} {count} ({percentage:.0f}%)\n"
    
    return response.strip()


def generate_sentiment_insight(analytics: dict) -> str:
    """Explain sentiment distribution in saved articles."""
    sentiment = analytics.get("sentiment_breakdown", {})
    total = sum(sentiment.values())
    
    if total == 0:
        return "I don't have sentiment data for your saved articles yet. The more articles you save, the better I can analyze the tone of your feed."
    
    positive = sentiment.get("Positive", 0)
    negative = sentiment.get("Negative", 0)
    neutral = sentiment.get("Neutral", 0)
    
    dominant = max(sentiment.items(), key=lambda x: x[1])[0]
    
    response = "ðŸ’­ **Sentiment Analysis of Your Saved Articles**\n\n"
    response += f"â€¢ ðŸŸ¢ Positive: {positive} articles ({positive/total*100:.0f}%)\n"
    response += f"â€¢ ðŸŸ¡ Neutral: {neutral} articles ({neutral/total*100:.0f}%)\n"
    response += f"â€¢ ðŸ”´ Negative: {negative} articles ({negative/total*100:.0f}%)\n\n"
    
    if dominant == "Negative" and negative > positive:
        response += "Your feed leans **negative**. This might be due to current events coverage. Consider balancing with uplifting stories from entertainment or technology sections."
    elif dominant == "Positive":
        response += "Your feed has a **positive** tone! You tend to save uplifting or optimistic news stories."
    else:
        response += "Your feed is **balanced**. You save a healthy mix of different news tones."
    
    return response


def generate_read_recommendation(bookmarks: list, read_later: list, analytics: dict) -> str:
    """Recommend what to read next."""
    # Prioritize read-later items
    if read_later:
        top_item = read_later[0]  # Most recent
        title = top_item.get("title", "Untitled")
        source = top_item.get("source", "Unknown")
        
        response = "ðŸ“– **My Recommendation**\n\n"
        response += f"Start with: **{title}** from {source}\n\n"
        response += f"_This is at the top of your Read Later list. You have {len(read_later)} items waiting!_"
        return response
    
    if bookmarks:
        # Recommend based on top category
        top_cat = analytics.get("top_category")
        for item in bookmarks:
            if item.get("category") == top_cat:
                title = item.get("title", "Untitled")
                response = f"ðŸ“– Based on your interest in **{top_cat}**, I recommend:\n\n"
                response += f"**{title}**"
                return response
        
        # Fallback to most recent
        title = bookmarks[0].get("title", "Untitled")
        return f"ðŸ“– Check out your most recent bookmark: **{title}**"
    
    return "You don't have any saved articles yet! Browse the feed and bookmark articles you'd like to read later."


def generate_explain_simple(article: Optional[dict]) -> str:
    """Simplify article explanation."""
    if not article:
        return "Please select an article first by clicking 'Ask AI about this article' on a news card."
    
    title = article.get("title", "")
    
    return f"ðŸ§’ **Simple Explanation**\n\nThe article '{title[:40]}...' talks about something happening in the news. To give you a kid-friendly explanation, I'd need the full article content. Try asking me after viewing the AI summary of this article!"


def generate_compare_articles(bookmarks: list, read_later: list) -> str:
    """Compare saved articles."""
    all_items = bookmarks + read_later
    
    if len(all_items) < 2:
        return "You need at least 2 saved articles to compare. Save more articles and try again!"
    
    item1, item2 = all_items[0], all_items[1]
    
    response = "âš–ï¸ **Comparing Your Two Most Recent Saves**\n\n"
    response += f"**Article 1:** {item1.get('title', 'Untitled')[:50]}\n"
    response += f"  â€¢ Source: {item1.get('source', 'Unknown')}\n"
    response += f"  â€¢ Category: {item1.get('category', 'general')}\n\n"
    response += f"**Article 2:** {item2.get('title', 'Untitled')[:50]}\n"
    response += f"  â€¢ Source: {item2.get('source', 'Unknown')}\n"
    response += f"  â€¢ Category: {item2.get('category', 'general')}\n\n"
    
    if item1.get("category") == item2.get("category"):
        response += f"_Both articles are about **{item1.get('category', 'general')}**._"
    else:
        response += "_These articles cover different topics._"
    
    return response


def generate_similar_read(bookmarks: list, read_later: list, analytics: dict) -> str:
    """Find similar articles based on category."""
    top_cat = analytics.get("top_category")
    all_items = bookmarks + read_later
    
    if not top_cat or not all_items:
        return "I need more data about your reading patterns. Save more articles and I'll find similar ones for you!"
    
    similar = [item for item in all_items if item.get("category") == top_cat]
    
    if len(similar) < 2:
        return f"You only have {len(similar)} article(s) in your top category ({top_cat}). Save more from this category!"
    
    response = f"ðŸ“Ž **Similar Articles in {top_cat.title()}**\n\n"
    for item in similar[:5]:
        response += f"â€¢ {item.get('title', 'Untitled')[:50]}\n"
    
    return response


def generate_greeting_response(analytics: dict) -> str:
    """Friendly greeting with context."""
    total = analytics.get("total_saved", 0)
    articles_read = analytics.get("articles_read", 0)
    
    response = "ðŸ‘‹ **Hello! I'm your NewsAura AI assistant.**\n\n"
    response += "I can help you with:\n"
    response += "â€¢ Summarizing your saved articles\n"
    response += "â€¢ Giving you a daily briefing\n"
    response += "â€¢ Answering questions about specific articles\n"
    response += "â€¢ Analyzing your reading patterns\n"
    response += "â€¢ Recommending what to read next\n\n"
    
    if total > 0:
        response += f"_You have **{total}** saved articles and have read **{articles_read}** summaries._"
    else:
        response += "_Start saving articles to get personalized insights!_"
    
    return response


def generate_help_response() -> str:
    """List chatbot capabilities."""
    return """ðŸ¤– **NewsAura AI Capabilities**

**What I can do:**
â€¢ "Summarize my saved articles" â€” Get an overview of all your bookmarks
â€¢ "Give me today's briefing" â€” Quick headlines from your interests
â€¢ "What topics do I read the most?" â€” Your reading pattern analysis
â€¢ "Why is my feed negative?" â€” Sentiment breakdown
â€¢ "What should I read first?" â€” Personalized recommendations
â€¢ "Compare two saved articles" â€” Side-by-side comparison
â€¢ "Have I read something similar?" â€” Find related articles

**Contextual questions:**
Click "Ask AI" on any article card to ask questions about specific articles.

_I only use your saved articles and reading history â€” no external lookups!_"""


def generate_fallback_response(message: str) -> str:
    """Fallback for unrecognized intents."""
    return f"""I'm not sure how to help with that specific request.

**Try asking me things like:**
â€¢ "Summarize my saved articles"
â€¢ "Give me a daily briefing"
â€¢ "What topics do I read the most?"
â€¢ "What should I read next?"

Or click "Ask AI" on an article card for article-specific questions!"""


# --------------------------------------------------
# Main Chat Endpoint
# --------------------------------------------------
@router.post("/message", response_model=ChatMessageResponse)
async def chat_message(
    request: ChatMessageRequest,
    user=Depends(get_current_user_optional),
    db=Depends(get_db),
):
    """
    Process a chat message and return a context-aware response.
    
    Flow:
    1. Detect intent from message
    2. Fetch relevant context (bookmarks, read-later, analytics)
    3. Try LLM response first (Ollama)
    4. Fallback to rule-based generators if LLM unavailable
    """
    user_id = user["user_id"]
    message = request.message.strip()
    context = request.context or {}
    
    if not message:
        raise HTTPException(status_code=400, detail="Message cannot be empty")
    
    logger.info("[CHATBOT] user_id=%s message=%s", user_id, message[:50])
    
    # Detect intent
    intent = detect_intent(message)
    
    # Article context override
    article_id = context.get("article_id")
    
    # Fetch user data + cached news
    bookmarks = await get_user_bookmarks(db, user_id)
    read_later = await get_user_read_later(db, user_id)
    analytics = await get_user_analytics(db, user_id)
    cached_articles = await get_cached_news_articles(limit_per_category=3)
    
    # Fetch specific article if referenced
    article = None
    if article_id:
        # Check user's saved items first, then fall back to cache
        article = await get_article_by_id(db, user_id, article_id)
        if not article:
            article = await find_article_in_cache(article_id)
    elif intent == "article_qa" and bookmarks:
        article = bookmarks[0]  # Default to most recent
    
    sources = []
    reply = ""
    used_llm = False
    
    # Determine data sources based on intent
    if intent in ("summarize_saved", "article_qa", "explain_simple", "compare_articles"):
        sources = ["bookmarks", "read_later", "news_cache"]
    elif intent in ("daily_briefing", "read_recommendation", "similar_read", "news_feed"):
        sources = ["bookmarks", "read_later", "analytics", "news_cache"]
    elif intent in ("top_topics", "sentiment_insight", "greeting"):
        sources = ["analytics"]
    elif intent == "help":
        sources = []
    else:
        sources = ["bookmarks", "read_later", "analytics", "news_cache"]
    
    # Build context for LLM
    llm_context = build_llm_context(
        bookmarks=bookmarks,
        read_later=read_later,
        analytics=analytics,
        article=article,
        intent=intent,
        cached_articles=cached_articles,
    )
    
    # Try LLM first (for non-trivial intents)
    if intent not in ("greeting", "help"):
        llm_response = await chat_llm.send_prompt(
            context=llm_context,
            user_message=message,
            intent=intent
        )
        
        if llm_response:
            reply = llm_response
            used_llm = True
            logger.info("[CHATBOT] Using LLM response for intent=%s", intent)
    
    # Fallback to rule-based generators
    if not reply:
        logger.info("[CHATBOT] Using fallback generator for intent=%s", intent)
        
        if intent == "summarize_saved":
            reply = generate_summarize_saved_response(bookmarks, read_later)
        
        elif intent == "daily_briefing":
            reply = generate_daily_briefing(bookmarks, read_later, analytics)
        
        elif intent == "article_qa" or article_id:
            reply = generate_article_qa_response(article, message)
        
        elif intent == "top_topics":
            reply = generate_top_topics_response(analytics)
        
        elif intent == "sentiment_insight":
            reply = generate_sentiment_insight(analytics)
        
        elif intent == "read_recommendation":
            reply = generate_read_recommendation(bookmarks, read_later, analytics)
        
        elif intent == "explain_simple":
            # Try LLM for ELI5 if article available
            if article and not used_llm:
                eli5_response = await chat_llm.explain_like_five(
                    article_title=article.get("title", ""),
                    article_content=article.get("description", "") or article.get("content", "")
                )
                if eli5_response:
                    reply = f"ðŸ§’ **Simple Explanation**\n\n{eli5_response}"
                    used_llm = True
            
            if not reply:
                reply = generate_explain_simple(article)
        
        elif intent == "compare_articles":
            reply = generate_compare_articles(bookmarks, read_later)
        
        elif intent == "similar_read":
            reply = generate_similar_read(bookmarks, read_later, analytics)
        
        elif intent == "greeting":
            reply = generate_greeting_response(analytics)
        
        elif intent == "help":
            reply = generate_help_response()
        
        else:
            # General query - try LLM one more time with context
            if not used_llm:
                llm_response = await chat_llm.send_prompt(
                    context=llm_context,
                    user_message=message,
                    intent="general_query"
                )
                if llm_response:
                    reply = llm_response
                    used_llm = True
            
            if not reply:
                reply = generate_fallback_response(message)
    
    # Optional: Store chat message
    try:
        await db.chat_messages.insert_one({
            "user_id": user_id,
            "role": "user",
            "content": message,
            "created_at": datetime.utcnow(),
        })
        await db.chat_messages.insert_one({
            "user_id": user_id,
            "role": "assistant",
            "content": reply,
            "intent": intent,
            "used_llm": used_llm,
            "created_at": datetime.utcnow(),
        })
    except Exception as e:
        logger.warning("[CHATBOT] Failed to store chat: %s", e)
    
    logger.info("[CHATBOT] intent=%s sources=%s used_llm=%s", intent, sources, used_llm)
    
    return ChatMessageResponse(
        reply=reply,
        intent=intent,
        sources=sources,
    )


# --------------------------------------------------
# Chat History Endpoint
# --------------------------------------------------
@router.get("/history")
async def get_chat_history(
    limit: int = 20,
    user=Depends(get_current_user_optional),
    db=Depends(get_db),
):
    """Get recent chat history for the user."""
    user_id = user["user_id"]
    
    cursor = db.chat_messages.find(
        {"user_id": user_id}
    ).sort("created_at", -1).limit(limit)
    
    messages = []
    async for doc in cursor:
        messages.append({
            "role": doc.get("role"),
            "content": doc.get("content"),
            "intent": doc.get("intent"),
            "created_at": doc.get("created_at"),
        })
    
    # Reverse to show oldest first
    messages.reverse()
    
    return {"messages": messages, "count": len(messages)}
